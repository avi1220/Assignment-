1- A) Lancaster Stemmer B) Porter Stemmer

2-A) All the words can be reduced to their base form
    B) so that we do not end up with too many words in the vocabulary which are not adding information to the model.
   C) so that lengths of words are reduced

3-D) All of the above

4-B) Chunking

5-A) These taggers assign that POS tag to the word whose frequency is maximum for that word in the training Corpus.

6-D) None of the above

7-D) None of the above

8-A) The transition probabilities refer to probabilities of transitioning from one tag to another tag.

9-B) ‘ate’

10-B) POS tagging

11-D) HMM based POS tagging

12-D) None of these

13-D) All of the above

14-B) It’s an algorithm of Bottom up parsing.

15-A) It is normalized form of a CFG.

16-C) Count-vectorization to create BOW for lexical level analysis.